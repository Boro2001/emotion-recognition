{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('train.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbox</th>\n",
       "      <th>paths</th>\n",
       "      <th>discrete_emotion</th>\n",
       "      <th>continous_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[86, 58, 564, 628]</td>\n",
       "      <td>./emotic/mscoco/images/COCO_val2014_0000005622...</td>\n",
       "      <td>[Disconnection, Doubt/Confusion]</td>\n",
       "      <td>[5, 3, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[485, 149, 605, 473]</td>\n",
       "      <td>./emotic/mscoco/images/COCO_train2014_00000028...</td>\n",
       "      <td>[Anticipation]</td>\n",
       "      <td>[6, 4, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[305, 92, 461, 465]</td>\n",
       "      <td>./emotic/mscoco/images/COCO_val2014_0000005581...</td>\n",
       "      <td>[Engagement, Excitement, Happiness]</td>\n",
       "      <td>[7, 8, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[221, 63, 448, 372]</td>\n",
       "      <td>./emotic/mscoco/images/COCO_train2014_00000036...</td>\n",
       "      <td>[Aversion, Pleasure]</td>\n",
       "      <td>[8, 9, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[44, 143, 150, 288]</td>\n",
       "      <td>./emotic/mscoco/images/COCO_train2014_00000021...</td>\n",
       "      <td>[Confidence, Excitement]</td>\n",
       "      <td>[7, 9, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17072</th>\n",
       "      <td>[189, 194, 323, 438]</td>\n",
       "      <td>./emotic/mscoco/images/COCO_val2014_0000002037...</td>\n",
       "      <td>[Anticipation, Engagement]</td>\n",
       "      <td>[6, 5, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17073</th>\n",
       "      <td>[214, 48, 340, 326]</td>\n",
       "      <td>./emotic/mscoco/images/COCO_train2014_00000017...</td>\n",
       "      <td>[Confidence]</td>\n",
       "      <td>[7, 8, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17074</th>\n",
       "      <td>[166, 35, 341, 401]</td>\n",
       "      <td>./emotic/mscoco/images/COCO_val2014_0000005140...</td>\n",
       "      <td>[Anticipation, Engagement, Excitement]</td>\n",
       "      <td>[6, 2, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17075</th>\n",
       "      <td>[245.0, 227.0, 293.0, 340.0]</td>\n",
       "      <td>./emotic/framesdb/images/frame_k7fb824vh221kl3...</td>\n",
       "      <td>[Engagement]</td>\n",
       "      <td>[5, 5, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17076</th>\n",
       "      <td>[189, 169, 314, 410]</td>\n",
       "      <td>./emotic/mscoco/images/COCO_val2014_0000002446...</td>\n",
       "      <td>[Sympathy]</td>\n",
       "      <td>[6, 4, 8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16896 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               bbox  \\\n",
       "0                [86, 58, 564, 628]   \n",
       "1              [485, 149, 605, 473]   \n",
       "2               [305, 92, 461, 465]   \n",
       "3               [221, 63, 448, 372]   \n",
       "4               [44, 143, 150, 288]   \n",
       "...                             ...   \n",
       "17072          [189, 194, 323, 438]   \n",
       "17073           [214, 48, 340, 326]   \n",
       "17074           [166, 35, 341, 401]   \n",
       "17075  [245.0, 227.0, 293.0, 340.0]   \n",
       "17076          [189, 169, 314, 410]   \n",
       "\n",
       "                                                   paths  \\\n",
       "0      ./emotic/mscoco/images/COCO_val2014_0000005622...   \n",
       "1      ./emotic/mscoco/images/COCO_train2014_00000028...   \n",
       "2      ./emotic/mscoco/images/COCO_val2014_0000005581...   \n",
       "3      ./emotic/mscoco/images/COCO_train2014_00000036...   \n",
       "4      ./emotic/mscoco/images/COCO_train2014_00000021...   \n",
       "...                                                  ...   \n",
       "17072  ./emotic/mscoco/images/COCO_val2014_0000002037...   \n",
       "17073  ./emotic/mscoco/images/COCO_train2014_00000017...   \n",
       "17074  ./emotic/mscoco/images/COCO_val2014_0000005140...   \n",
       "17075  ./emotic/framesdb/images/frame_k7fb824vh221kl3...   \n",
       "17076  ./emotic/mscoco/images/COCO_val2014_0000002446...   \n",
       "\n",
       "                             discrete_emotion continous_emotion  \n",
       "0            [Disconnection, Doubt/Confusion]         [5, 3, 9]  \n",
       "1                              [Anticipation]         [6, 4, 7]  \n",
       "2         [Engagement, Excitement, Happiness]         [7, 8, 8]  \n",
       "3                        [Aversion, Pleasure]         [8, 9, 8]  \n",
       "4                    [Confidence, Excitement]        [7, 9, 10]  \n",
       "...                                       ...               ...  \n",
       "17072              [Anticipation, Engagement]         [6, 5, 3]  \n",
       "17073                            [Confidence]         [7, 8, 7]  \n",
       "17074  [Anticipation, Engagement, Excitement]        [6, 2, 10]  \n",
       "17075                            [Engagement]         [5, 5, 6]  \n",
       "17076                              [Sympathy]         [6, 4, 8]  \n",
       "\n",
       "[16896 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. YOLOv3\n",
    "# 2. GoogleNet\n",
    "# 3. ResNet\n",
    "# 4. InceptionV3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mikolajborowicz/Desktop/emotion-recognition/neural-network-training.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mikolajborowicz/Desktop/emotion-recognition/neural-network-training.ipynb#ch0000005?line=7'>8</a>\u001b[0m x2 \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mbbox\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m2\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mikolajborowicz/Desktop/emotion-recognition/neural-network-training.ipynb#ch0000005?line=8'>9</a>\u001b[0m y2 \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mbbox\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m3\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mikolajborowicz/Desktop/emotion-recognition/neural-network-training.ipynb#ch0000005?line=9'>10</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(row[\u001b[39m'\u001b[39;49m\u001b[39mpaths\u001b[39;49m\u001b[39m'\u001b[39;49m])[y1:y2, x1:x2]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikolajborowicz/Desktop/emotion-recognition/neural-network-training.ipynb#ch0000005?line=10'>11</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m, img)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikolajborowicz/Desktop/emotion-recognition/neural-network-training.ipynb#ch0000005?line=11'>12</a>\u001b[0m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "# image prepearation\n",
    "import cv2\n",
    "import os\n",
    "for i, row in data.iterrows():\n",
    "    # display cropped image using bbox\n",
    "    x1 = row['bbox'][0]\n",
    "    y1 = row['bbox'][1]\n",
    "    x2 = row['bbox'][2]\n",
    "    y2 = row['bbox'][3]\n",
    "    img = cv2.imread(row['paths'])[y1:y2, x1:x2]\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62a727df985e3daf18bc9d1942c89ef5df65520a7e91f46a7d19652d0d54c774"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
