{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'test', 'train', 'val'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading annotations \n",
    "mat = sio.loadmat('Annotations/Annotations.mat')\n",
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array(['COCO_val2014_000000562243.jpg'], dtype='<U29'), array(['mscoco/images'], dtype='<U13'), array([[(array([[640]], dtype=uint16), array([[640]], dtype=uint16))]],\n",
      "       dtype=[('n_col', 'O'), ('n_row', 'O')]), array([[(array(['mscoco'], dtype='<U6'), array([[(array([[562243]], dtype=int32), array([[448867]], dtype=int32))]],\n",
      "               dtype=[('image_id', 'O'), ('annotations_id', 'O')]))                                                  ]],\n",
      "       dtype=[('name', 'O'), ('info', 'O')]), array([[(array([[ 86,  58, 564, 628]], dtype=uint16), array([[(array([[array(['Disconnection'], dtype='<U13'),\n",
      "                         array(['Doubt/Confusion'], dtype='<U15')]], dtype=object),)]],\n",
      "               dtype=[('categories', 'O')]), array([[(array([[5]], dtype=uint8), array([[3]], dtype=uint8), array([[9]], dtype=uint8))]],\n",
      "               dtype=[('valence', 'O'), ('arousal', 'O'), ('dominance', 'O')]), array(['Male'], dtype='<U4'), array(['Adult'], dtype='<U5'))]],\n",
      "       dtype=[('body_bbox', 'O'), ('annotations_categories', 'O'), ('annotations_continuous', 'O'), ('gender', 'O'), ('age', 'O')]))\n",
      " (array(['COCO_train2014_000000288841.jpg'], dtype='<U31'), array(['mscoco/images'], dtype='<U13'), array([[(array([[640]], dtype=uint16), array([[480]], dtype=uint16))]],\n",
      "       dtype=[('n_col', 'O'), ('n_row', 'O')]), array([[(array(['mscoco'], dtype='<U6'), array([[(array([[288841]], dtype=int32), array([[1750456]], dtype=int32))]],\n",
      "               dtype=[('image_id', 'O'), ('annotations_id', 'O')]))                                                   ]],\n",
      "       dtype=[('name', 'O'), ('info', 'O')]), array([[(array([[485, 149, 605, 473]], dtype=uint16), array([[(array([[array(['Anticipation'], dtype='<U12')]], dtype=object),)]],\n",
      "               dtype=[('categories', 'O')]), array([[(array([[6]], dtype=uint8), array([[4]], dtype=uint8), array([[7]], dtype=uint8))]],\n",
      "               dtype=[('valence', 'O'), ('arousal', 'O'), ('dominance', 'O')]), array(['Male'], dtype='<U4'), array(['Adult'], dtype='<U5'))]],\n",
      "       dtype=[('body_bbox', 'O'), ('annotations_categories', 'O'), ('annotations_continuous', 'O'), ('gender', 'O'), ('age', 'O')]))\n",
      " (array(['COCO_val2014_000000558171.jpg'], dtype='<U29'), array(['mscoco/images'], dtype='<U13'), array([[(array([[640]], dtype=uint16), array([[480]], dtype=uint16))]],\n",
      "       dtype=[('n_col', 'O'), ('n_row', 'O')]), array([[(array(['mscoco'], dtype='<U6'), array([[(array([[558171]], dtype=int32), array([[467799]], dtype=int32))]],\n",
      "               dtype=[('image_id', 'O'), ('annotations_id', 'O')]))                                                  ]],\n",
      "       dtype=[('name', 'O'), ('info', 'O')]), array([[(array([[305,  92, 461, 465]], dtype=uint16), array([[(array([[array(['Engagement'], dtype='<U10'),\n",
      "                         array(['Excitement'], dtype='<U10'),\n",
      "                         array(['Happiness'], dtype='<U9')]], dtype=object),)]],\n",
      "               dtype=[('categories', 'O')]), array([[(array([[7]], dtype=uint8), array([[8]], dtype=uint8), array([[8]], dtype=uint8))]],\n",
      "               dtype=[('valence', 'O'), ('arousal', 'O'), ('dominance', 'O')]), array(['Male'], dtype='<U4'), array(['Teenager'], dtype='<U8'))]],\n",
      "       dtype=[('body_bbox', 'O'), ('annotations_categories', 'O'), ('annotations_continuous', 'O'), ('gender', 'O'), ('age', 'O')]))\n",
      " ...\n",
      " (array(['COCO_val2014_000000514083.jpg'], dtype='<U29'), array(['mscoco/images'], dtype='<U13'), array([[(array([[640]], dtype=uint16), array([[480]], dtype=uint16))]],\n",
      "       dtype=[('n_col', 'O'), ('n_row', 'O')]), array([[(array(['mscoco'], dtype='<U6'), array([[(array([[514083]], dtype=int32), array([[432213]], dtype=int32))]],\n",
      "               dtype=[('image_id', 'O'), ('annotations_id', 'O')]))                                                  ]],\n",
      "       dtype=[('name', 'O'), ('info', 'O')]), array([[(array([[166,  35, 341, 401]], dtype=uint16), array([[(array([[array(['Anticipation'], dtype='<U12'),\n",
      "                         array(['Engagement'], dtype='<U10'),\n",
      "                         array(['Excitement'], dtype='<U10')]], dtype=object),)]],\n",
      "               dtype=[('categories', 'O')]), array([[(array([[6]], dtype=uint8), array([[2]], dtype=uint8), array([[10]], dtype=uint8))]],\n",
      "               dtype=[('valence', 'O'), ('arousal', 'O'), ('dominance', 'O')]), array(['Male'], dtype='<U4'), array(['Adult'], dtype='<U5'))]],\n",
      "       dtype=[('body_bbox', 'O'), ('annotations_categories', 'O'), ('annotations_continuous', 'O'), ('gender', 'O'), ('age', 'O')]))\n",
      " (array(['frame_k7fb824vh221kl3j.jpg'], dtype='<U26'), array(['framesdb/images'], dtype='<U15'), array([[(array([[500]], dtype=uint16), array([[375]], dtype=uint16))]],\n",
      "       dtype=[('n_col', 'O'), ('n_row', 'O')]), array([[(array(['framesdb'], dtype='<U8'),)]], dtype=[('name', 'O')]), array([[(array([[245., 227., 293., 340.]], dtype=float32), array([[(array([[array(['Engagement'], dtype='<U10')]], dtype=object),)]],\n",
      "               dtype=[('categories', 'O')]), array([[(array([[5]], dtype=uint8), array([[5]], dtype=uint8), array([[6]], dtype=uint8))]],\n",
      "               dtype=[('valence', 'O'), ('arousal', 'O'), ('dominance', 'O')]), array(['Male'], dtype='<U4'), array(['Adult'], dtype='<U5'))]],\n",
      "       dtype=[('body_bbox', 'O'), ('annotations_categories', 'O'), ('annotations_continuous', 'O'), ('gender', 'O'), ('age', 'O')]))\n",
      " (array(['COCO_val2014_000000244665.jpg'], dtype='<U29'), array(['mscoco/images'], dtype='<U13'), array([[(array([[640]], dtype=uint16), array([[480]], dtype=uint16))]],\n",
      "       dtype=[('n_col', 'O'), ('n_row', 'O')]), array([[(array(['mscoco'], dtype='<U6'), array([[(array([[244665]], dtype=int32), array([[1288561]], dtype=int32))]],\n",
      "               dtype=[('image_id', 'O'), ('annotations_id', 'O')]))                                                   ]],\n",
      "       dtype=[('name', 'O'), ('info', 'O')]), array([[(array([[189, 169, 314, 410]], dtype=uint16), array([[(array([[array(['Sympathy'], dtype='<U8')]], dtype=object),)]],\n",
      "               dtype=[('categories', 'O')]), array([[(array([[6]], dtype=uint8), array([[4]], dtype=uint8), array([[8]], dtype=uint8))]],\n",
      "               dtype=[('valence', 'O'), ('arousal', 'O'), ('dominance', 'O')]), array(['Female'], dtype='<U6'), array(['Adult'], dtype='<U5')),\n",
      "         (array([[303, 174, 535, 468]], dtype=uint16), array([[(array([[array(['Anticipation'], dtype='<U12'),\n",
      "                         array(['Esteem'], dtype='<U6'), array(['Sympathy'], dtype='<U8')]],\n",
      "                       dtype=object),)                                                      ]],\n",
      "               dtype=[('categories', 'O')]), array([[(array([[7]], dtype=uint8), array([[6]], dtype=uint8), array([[7]], dtype=uint8))]],\n",
      "               dtype=[('valence', 'O'), ('arousal', 'O'), ('dominance', 'O')]), array(['Male'], dtype='<U4'), array(['Adult'], dtype='<U5'))]],\n",
      "       dtype=[('body_bbox', 'O'), ('annotations_categories', 'O'), ('annotations_continuous', 'O'), ('gender', 'O'), ('age', 'O')]))                                       ]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'clear'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/mikolajborowicz/Desktop/emotion-recognition/data-preparation.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mikolajborowicz/Desktop/emotion-recognition/data-preparation.ipynb#ch0000006?line=4'>5</a>\u001b[0m train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(mat[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mikolajborowicz/Desktop/emotion-recognition/data-preparation.ipynb#ch0000006?line=5'>6</a>\u001b[0m test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(mat[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mikolajborowicz/Desktop/emotion-recognition/data-preparation.ipynb#ch0000006?line=6'>7</a>\u001b[0m os\u001b[39m.\u001b[39;49mclear()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute 'clear'"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(type(mat['train']))\n",
    "# print(mat['train'].shape)\n",
    "print(mat['train'][0])\n",
    "# convert mat [train, test] to pandas dataframe\n",
    "train = pd.DataFrame(mat['train'][0])\n",
    "test = pd.DataFrame(mat['test'][0])\n",
    "os.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'person'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/mikolajborowicz/Desktop/emotion-recognition/data-preparation.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mikolajborowicz/Desktop/emotion-recognition/data-preparation.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(train[\u001b[39m\"\u001b[39;49m\u001b[39mperson\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mvalue_counts())\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pandas/core/indexes/range.py:389\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m    390\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mget_loc(key, method\u001b[39m=\u001b[39mmethod, tolerance\u001b[39m=\u001b[39mtolerance)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'person'"
     ]
    }
   ],
   "source": [
    "print(train[\"person\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28821 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# number of images to feed into the NN for every batch\n",
    "batch_size = 128\n",
    "\n",
    "datagen_train = ImageDataGenerator()\n",
    "datagen_validation = ImageDataGenerator()\n",
    "\n",
    "train_generator = datagen_train.flow_from_directory(base_path + \"train\",\n",
    "                                                    target_size=(pic_size,pic_size),\n",
    "                                                    color_mode=\"grayscale\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "validation_generator = datagen_validation.flow_from_directory(base_path + \"validation\",\n",
    "                                                    target_size=(pic_size,pic_size),\n",
    "                                                    color_mode=\"grayscale\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62a727df985e3daf18bc9d1942c89ef5df65520a7e91f46a7d19652d0d54c774"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
